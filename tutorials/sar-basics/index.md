---
title: SAR basics
description: Introduction to SAR basics using Sentinel-1 in GEE.
author: glemoine62
tags: SAR, Sentinel-1, Copernicus, backscattering coefficients, GRD, polarization
date_published: 2020-08-20
---
<!--
Copyright 2019 The Google Earth Engine Community Authors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

This tutorial introduces the basics for Sentinel-1 use in GEE. It will illustrate basic SAR terminology and demonstrate data selection and visualization.
In a next tutorial, we'll introduce more advanced concepts.

## SAR characteristics

A good introduction into Synthetic Aperture Radar (SAR) basics is [A Tutorial on Synthetic Aperture Radar](https://elib.dlr.de/82313/) by a group of experts at DLR led by Dr. A. Moreira. The essentials are in part I and II. Advanced polarimetry and interferometry, or combined POLINSAR, (part III *ff*) is currently outside the scope of what is possible in GEE.

The key difference between SAR and optical sensors is that

- SAR is an **active** sensor, transmitting **microwave** radiation, for which it receives the portion **scattered back** to the sensor. Optical sensors are **passive** sensors that register reflected radiation from the Sun (in specific parts of the visible and infrared spectrum).
- SAR is **side-looking**, unlike optical sensors which are, usually, nadir looking. 
- SAR radiation is **coherent**, within a pre-set range of wavelengths. This is useful, because it allows precise **phase** and **intensity** measurements and the use of **polarization**. However, it is also the cause of **speckle**. Optical sensors are not coherent, apart from laser and lidar instruments. 

Reflecting on these differences is important, because it is the basis to understand the relative advantages of SAR compared to optical sensors:

- SAR does not depend on Sun light, thus works **day and night**, provided the sensor acquires data
- SAR is **insensitive to the atmosphere** in C-band (Sentinel-1, except for very dense rain cells) and L-band (ALOS-PALSAR), both of which are in GEE collections. 
- SAR backscattering (intensity) depends on **different physical properties of the "target"** compared to the properties that cause reflectance in optical sensors. These properties relate to the structural geometry and (electromagnetic) material properties of what is illuminated by the incident radiation.
- SAR data can be **calibrated**, without the need for atmospheric correction, leading to **consistent time series**

as well as the disadvantages:

- The coherent nature of the SAR microwave radiation causes **speckle**. This causes the "salt and pepper" appearance of extended target areas (e.g. a large homogeneous agricultural field) that one would expect to have a constant backscattering behavior. Speckle can be reduced in different ways (see next tutorial), but is difficult to eliminate. 
- SAR backscattering depends on the **angle of the incident microwave radiation**. Thus, since the side-looking SAR operates over a range of incidence angles, the same target will appear different whether it is in near range (low incidence angle) or far range (higher incidence angle) of the scene. The manner in which the backscattering varies with incidence angle depends on the target: a flat dry soil surface has a stronger drop off with incidence angle than, for instance, a forest.
- **Terrain relief** has a strong effect on SAR backscattering because it modulates the area that is illuminated by the side-looking SAR radiation. Slope angle determines the orientation with respect to the incident radiation. This causes foreshortening for slopes oriented towards the SAR and shadowing of slopes steeper than the local incidence and directed away from the SAR.

## Sentinel-1

Let's look at some of the issues outlined above and how these relate to practical use of Sentinel-1. Sentinel sensor data is generated by the European Union's Copernicus program, which has the operational support of the European Space Agency (ESA). Copernicus Sentinel data is made available under a [full, free and open license](https://sentinel.esa.int/documents/247904/690755/Sentinel_Data_Legal_Notice). This license makes it possible for Google to integrate the data in their catalog of collections and expose it to the many GEE users.

SAR is a radar (RAdio Detection And Ranging) instrument, and it's basic measurements are intensity and phase measurements of the backscattered signal, sampled in time bins. These time bins relate to locations on Earth from which the backscattered signal originate. The "Synthetic Aperture" of the SAR is the virtual creation of a huge antenna which makes use of the sensor motion and the associated complex data processing, which is necessary to create high resolution in range. By moving along the orbit, the next azimuth line is created from a new microwave pulse in the range direction (this is oversimplified)

ESA applies SAR processing to generate Level-1 data from raw Sentinel-1 signal data in 2 formats: Single Look Complex (SLC) and Ground Range Detected (GRD). SLC is required for interferometric and partial polarimetric parameter extraction (it contains the phase information), whereas GRD is intensity ("detected") data sampled in ground range. Google collects the GRD data.

The Level-1 GRD processing assumes an elliptoid Earth surface model, and [Level-1 GRD needs to be processed to create the Level-2 geocoded, calibrated backscattering coefficients](https://developers.google.com/earth-engine/sentinel1#sentinel-1-preprocessing) which end up in the GEE COPERNICUS/S1_GRD_FLOAT collection.

The S1_GRD_FLOAT collection, and its log-scaled S1_GRD computed equivalent, contains "application ready" images, as they have square pixel spacing, with pixel values as FLOAT32, and a projection which defaults to the one of the local UTM zone. Thus, they can be combined with other images, used in feature extractions and reductions, etc.

### Sentinel-1 coverage

Sentinel-1 consists of 2 identical A and B sensors, which have a 12 days revisit orbit each, but a 6 days revisit when combined. However, there are certain limitations to how much data can be acquired and downloaded from the 2 sensors, which depend on system uptime per orbit, ground station visibility for data downlinking and some other factors. The maps in [the observation scenario plan](https://sentinel.esa.int/web/sentinel/missions/sentinel-1/observation-scenario) show actual and planned operations, which provide an initial idea on how certain areas are revisited.

For a more precise estimate, you can use GEE as follows:

```
// Use comments to describe details that can't be easily expressed in code.
// Always try making code more self descriptive before adding a comment.
// Similarly, avoid repeating verbatim what's already said in code
// (e.g., "assign ImageCollection to variable 'coll'").
var coll = ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA');
```

### Sentinel-1 orbits

And:

- This is a bulleted list.
- Use bulleted lists when items are not strictly ordered.

..and even:

Use     | tables   | to organize | content
------- | -------- | ----------- | -------
Your    | tables   | can         | also
contain | multiple | rows        | ...

## Section heading 2

Use separate sections for related, but discrete, groups of steps.

Use code blocks to show users how to do something after describing it:



### Use subsections if appropriate

Consider breaking longer sections that cover multiple topics or span multiple
pages into subsections.
